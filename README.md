# ğŸ“„ AI Multi-PDF RAG Chatbot (Local LLM)

A full-stack AI application that allows users to upload multiple PDFs and ask
natural-language questions over them using Retrieval-Augmented Generation (RAG).
The system runs **entirely locally** using a local LLM (Ollama), with streaming
responses and a modern chat UI.

---

## ğŸš€ Features

- ğŸ“‚ Upload and index **multiple PDFs**
- ğŸ” Semantic search using **vector embeddings**
- ğŸ§  Retrieval-Augmented Generation (RAG)
- ğŸ’¬ **Streaming chat responses** (real-time)
- ğŸ“ **Markdown & code-block rendering**
- âš¡ Local LLM inference using **Ollama** (no API cost)
- ğŸ’¾ Persistent vector storage with **ChromaDB**
- ğŸŒ™ Modern full-screen React UI

---

## ğŸ§  Tech Stack

**Frontend**
- React (Vite)
- Streaming Fetch API
- react-markdown + remark-gfm

**Backend**
- FastAPI
- ChromaDB (persistent vector store)
- PyPDF (PDF parsing)
- Ollama (local LLM + embeddings)

**Models**
- LLM: `llama2`
- Embeddings: `nomic-embed-text`

---

## ğŸ— Architecture
React (Chat UI)
â†“
FastAPI (API + Streaming)
â†“
ChromaDB (Vector Store)
â†“
Ollama (Local LLM & Embeddings)


---

## âš™ï¸ How It Works

1. User uploads one or more PDFs
2. PDFs are chunked and embedded
3. Embeddings are stored in ChromaDB
4. User asks a question
5. Relevant chunks are retrieved via cosine similarity
6. Context is injected into the prompt
7. Local LLM generates a **streamed response**

---

## ğŸ§ª Example Questions

- â€œSummarize this documentâ€
- â€œWhat is this PDF mainly about?â€
- â€œExplain this concept with a code exampleâ€
- â€œCompare topics across multiple PDFsâ€

---

## ğŸ“Œ Why This Project Matters

This project demonstrates:
- Real-world RAG system design
- Streaming AI UX
- LLM provider abstraction (cloud â†’ local)
- Cost-efficient AI engineering
- End-to-end system thinking

---

## ğŸ“¸ Screenshots

> See screenshots folder for UI and architecture visuals.

---

## ğŸ§© Future Improvements

- Document-level filtering
- Chat history & memory
- Authentication
- Deployment (Vercel + Render)

---
## ğŸŒ Live Demo

Frontend is deployed on Vercel.

> âš ï¸ Note: Backend runs locally using a local LLM (Ollama) and is not publicly hosted.

Live URL: pdf-rag-chat-ai-by-jaz.vercel.app


## ğŸ‘¨â€ğŸ’» Author

Built by **[Muhammed jazim T]**  
AI / ML Engineering Enthusiast# PDF-RAG-CHAT-AI-BY-JAZ-
